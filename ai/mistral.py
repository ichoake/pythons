import os
from pathlib import Path

import logging

logger = logging.getLogger(__name__)


# Load environment variables from ~/.env.d
def load_env_d():
    """Load all .env files from ~/.env.d directory"""
    env_d_path = Path.home() / '.env.d'
    if env_d_path.exists():
        for env_file in env_d_path.glob('*.env'):
            with open(env_file) as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"').strip("'")
                        if not key.startswith('source'):
                            os.environ[key] = value

load_env_d()

# -*- coding: utf-8 -*-
"""Mistral AI API quickstart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lh2Uc6h2BRkSVXhzyewGHRjhXWvkz9Rq

# Getting started with Mistral AI API
"""

! pip install mistralai

"""Our API is currently available through [La Plateforme](https://console.mistral.ai/). You need to activate payments on your account to enable your API keys. After a few moments, you will be able to use our `chat` endpoint:"""

from mistralai import Mistral
api_key=os.getenv("ELEVENLABS_API_KEY")
model = "mistral-large-latest"

client = Mistral(api_key=api_key)

chat_response = client.chat.complete(
    model=model,
    messages=[{"role":"user", "content":"What is the best French cheese?"}]
)

logger.info(chat_response.choices[0].message.content)

"""Or our embeddings endpoint:"""

model = "mistral-embed"

embeddings_response = client.embeddings.create(
    model=model,
    inputs=["Embed this sentence.", "As well as this one."]
)

logger.info(embeddings_response)